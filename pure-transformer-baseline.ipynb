{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New baseline for the bovine with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspired from this guide :\n",
    "https://keras.io/examples/vision/video_transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data, get_test_data, WeightedClassificationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#CPU\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  \n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import imageio\n",
    "import ipywidgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed for reproducibility\n",
    "SEED = 42\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = (30, 226, 226, 1)\n",
    "NUM_CLASSES = 8\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 160\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (9, 60, 60)\n",
    "STRIDES= tuple(list(map(lambda x:x//2, PATCH_SIZE)))\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 128\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 30, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STRIDES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_train, labels_train = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_classifier= np.array(videos_train)\n",
    "y_for_classifier= labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_test, labels_test  = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_for_classifier = np.array(videos_test)\n",
    "ytest_for_classifier = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_frames(video):\n",
    "    res=[]\n",
    "    for frame in video:\n",
    "        resized_img=Image.fromarray(frame).resize(INPUT_SHAPE[1:3])\n",
    "        res.append(np.array(resized_img))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that gets all dataset\n",
    "# 30 frames per video for 177 video = 2.65 gb !if considering each frame of float64\n",
    "# as uint8 it takes 0.33 gb\n",
    "\n",
    "def gen_videos(videolist):\n",
    "    newvideos=[] # 177*30*250*250\n",
    "    for video in videolist:\n",
    "        reducedvideo= video.read_samples(video.frame_times[0:299:10])\n",
    "        reducedvideo= reducedvideo.astype('uint8')        \n",
    "        #CROP from 250 to 224\n",
    "        reducedvideo=resize_frames(reducedvideo)\n",
    "        #and add a batch dimension. dim= 1*30*250*250*3\n",
    "        #reducedvideo = reducedvideo[None, ...]\n",
    "\n",
    "        newvideos.append(reducedvideo)\n",
    "    return newvideos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 30, 226, 226)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_for_classifier= np.array(gen_videos(X_for_classifier))\n",
    "X_for_classifier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 30, 226, 226)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_for_classifier= np.array(gen_videos(Xtest_for_classifier))\n",
    "Xtest_for_classifier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 30, 226, 226)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_videos=X_for_classifier\n",
    "test_videos=Xtest_for_classifier\n",
    "train_videos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_int(argument):\n",
    "    switcher = {\n",
    "        'A':0,\n",
    "        'B':1,\n",
    "        'C':2,\n",
    "        'D':3,\n",
    "        'E':4,\n",
    "        'F':5,\n",
    "        'G':6,\n",
    "        'H':7,\n",
    "    }\n",
    " \n",
    "    # get() method of dictionary data type returns\n",
    "    # value of passed argument if it is present\n",
    "    # in dictionary otherwise second argument will\n",
    "    # be assigned as default value of passed argument\n",
    "    return switcher.get(argument, \"nothing\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "func=np.vectorize(class_to_int)\n",
    "#Train\n",
    "train_labels=func(y_for_classifier)\n",
    "#Test\n",
    "test_labels=func(ytest_for_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
    "    \"\"\"Preprocess the frames tensors and parse the labels.\"\"\"\n",
    "    # Preprocess images\n",
    "    frames = tf.image.convert_image_dtype(\n",
    "        frames[\n",
    "            ..., tf.newaxis\n",
    "        ],  # The new axis is to help for further processing with Conv3D layers\n",
    "        tf.float32,\n",
    "    )\n",
    "    # Parse label\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return frames, label\n",
    "\n",
    "\n",
    "def prepare_dataloader(\n",
    "    videos: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    loader_type: str = \"train\",\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "):\n",
    "    \"\"\"Utility function to prepare the dataloader.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
    "\n",
    "    if loader_type == \"train\":\n",
    "        dataset = dataset.shuffle(BATCH_SIZE * 2)\n",
    "\n",
    "    dataloader = (\n",
    "        dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "trainloader = prepare_dataloader(train_videos, train_labels, \"train\")\n",
    "testloader = prepare_dataloader(test_videos, test_labels, \"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(trainloader )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size,strides, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=strides,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "\n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "\n",
    "        return flattened_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "inp = Input(shape=INPUT_SHAPE)\n",
    "out = TubeletEmbedding(\n",
    "    embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE, strides=STRIDES\n",
    ")(inp)\n",
    "model = Model(inp, out)\n",
    "\n",
    "output = model.predict(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 216, 128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokens, output_dim=self.embed_dim\n",
    "        )\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "\n",
    "    def call(self, encoded_tokens):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_tokens = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vivit_classifier(\n",
    "    tubelet_embedder,\n",
    "    positional_encoder,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    transformer_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embed_dim=PROJECTION_DIM,\n",
    "    layer_norm_eps=LAYER_NORM_EPS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "):\n",
    "    # Get the input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches.\n",
    "    patches = tubelet_embedder(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = positional_encoder(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization and MHSA\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
    "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
    "            ]\n",
    "        )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
    "    representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "    # Classify outputs.\n",
    "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "6/6 [==============================] - 7s 157ms/step - loss: 2.2065 - accuracy: 0.2034 - top-5-accuracy: 0.7345\n",
      "Epoch 2/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 2.0570 - accuracy: 0.2486 - top-5-accuracy: 0.7458\n",
      "Epoch 3/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 2.0143 - accuracy: 0.2147 - top-5-accuracy: 0.7684\n",
      "Epoch 4/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9961 - accuracy: 0.2260 - top-5-accuracy: 0.7853\n",
      "Epoch 5/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9972 - accuracy: 0.2203 - top-5-accuracy: 0.7797\n",
      "Epoch 6/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9865 - accuracy: 0.2147 - top-5-accuracy: 0.7571\n",
      "Epoch 7/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9763 - accuracy: 0.2429 - top-5-accuracy: 0.8136\n",
      "Epoch 8/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9710 - accuracy: 0.2486 - top-5-accuracy: 0.7966\n",
      "Epoch 9/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9644 - accuracy: 0.2486 - top-5-accuracy: 0.8136\n",
      "Epoch 10/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9531 - accuracy: 0.2486 - top-5-accuracy: 0.8192\n",
      "Epoch 11/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9547 - accuracy: 0.2486 - top-5-accuracy: 0.8136\n",
      "Epoch 12/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9554 - accuracy: 0.2486 - top-5-accuracy: 0.8079\n",
      "Epoch 13/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9448 - accuracy: 0.2486 - top-5-accuracy: 0.8136\n",
      "Epoch 14/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9469 - accuracy: 0.2486 - top-5-accuracy: 0.7966\n",
      "Epoch 15/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9441 - accuracy: 0.2486 - top-5-accuracy: 0.8136\n",
      "Epoch 16/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.9438 - accuracy: 0.2486 - top-5-accuracy: 0.8249\n",
      "Epoch 17/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.9371 - accuracy: 0.2486 - top-5-accuracy: 0.8192\n",
      "Epoch 18/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9581 - accuracy: 0.1525 - top-5-accuracy: 0.8136\n",
      "Epoch 19/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9356 - accuracy: 0.2486 - top-5-accuracy: 0.8305\n",
      "Epoch 20/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9390 - accuracy: 0.2486 - top-5-accuracy: 0.8249\n",
      "Epoch 21/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9377 - accuracy: 0.2712 - top-5-accuracy: 0.8249\n",
      "Epoch 22/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9329 - accuracy: 0.2599 - top-5-accuracy: 0.8192\n",
      "Epoch 23/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9288 - accuracy: 0.2486 - top-5-accuracy: 0.8362\n",
      "Epoch 24/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9326 - accuracy: 0.2429 - top-5-accuracy: 0.8249\n",
      "Epoch 25/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9275 - accuracy: 0.2486 - top-5-accuracy: 0.8023\n",
      "Epoch 26/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9351 - accuracy: 0.2486 - top-5-accuracy: 0.8305\n",
      "Epoch 27/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9438 - accuracy: 0.1921 - top-5-accuracy: 0.8192\n",
      "Epoch 28/160\n",
      "6/6 [==============================] - 1s 157ms/step - loss: 1.9082 - accuracy: 0.2938 - top-5-accuracy: 0.8305\n",
      "Epoch 29/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.9408 - accuracy: 0.2486 - top-5-accuracy: 0.8192\n",
      "Epoch 30/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.9210 - accuracy: 0.2316 - top-5-accuracy: 0.8079\n",
      "Epoch 31/160\n",
      "6/6 [==============================] - 1s 157ms/step - loss: 1.9193 - accuracy: 0.2599 - top-5-accuracy: 0.8305\n",
      "Epoch 32/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.9151 - accuracy: 0.2542 - top-5-accuracy: 0.8136\n",
      "Epoch 33/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9270 - accuracy: 0.2429 - top-5-accuracy: 0.8475\n",
      "Epoch 34/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9178 - accuracy: 0.2768 - top-5-accuracy: 0.8136\n",
      "Epoch 35/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.9091 - accuracy: 0.2429 - top-5-accuracy: 0.8305\n",
      "Epoch 36/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.9268 - accuracy: 0.2147 - top-5-accuracy: 0.8362\n",
      "Epoch 37/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9153 - accuracy: 0.2655 - top-5-accuracy: 0.8362\n",
      "Epoch 38/160\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 1.9091 - accuracy: 0.2599 - top-5-accuracy: 0.8644\n",
      "Epoch 39/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9254 - accuracy: 0.2542 - top-5-accuracy: 0.8531\n",
      "Epoch 40/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.9106 - accuracy: 0.2881 - top-5-accuracy: 0.8475\n",
      "Epoch 41/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.9267 - accuracy: 0.2373 - top-5-accuracy: 0.8249\n",
      "Epoch 42/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.9009 - accuracy: 0.2938 - top-5-accuracy: 0.7853\n",
      "Epoch 43/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.8966 - accuracy: 0.2768 - top-5-accuracy: 0.8475\n",
      "Epoch 44/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.8987 - accuracy: 0.2881 - top-5-accuracy: 0.8814\n",
      "Epoch 45/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9041 - accuracy: 0.2938 - top-5-accuracy: 0.8362\n",
      "Epoch 46/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.8832 - accuracy: 0.2994 - top-5-accuracy: 0.8418\n",
      "Epoch 47/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.9037 - accuracy: 0.2599 - top-5-accuracy: 0.8475\n",
      "Epoch 48/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.8965 - accuracy: 0.2825 - top-5-accuracy: 0.8249\n",
      "Epoch 49/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.8842 - accuracy: 0.2655 - top-5-accuracy: 0.8418\n",
      "Epoch 50/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.8864 - accuracy: 0.2599 - top-5-accuracy: 0.8531\n",
      "Epoch 51/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.8677 - accuracy: 0.2994 - top-5-accuracy: 0.8305\n",
      "Epoch 52/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.8876 - accuracy: 0.2825 - top-5-accuracy: 0.8418\n",
      "Epoch 53/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.8685 - accuracy: 0.3164 - top-5-accuracy: 0.8475\n",
      "Epoch 54/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.8582 - accuracy: 0.3164 - top-5-accuracy: 0.8418\n",
      "Epoch 55/160\n",
      "6/6 [==============================] - 1s 175ms/step - loss: 1.8765 - accuracy: 0.2994 - top-5-accuracy: 0.8249\n",
      "Epoch 56/160\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 1.8567 - accuracy: 0.3051 - top-5-accuracy: 0.8644\n",
      "Epoch 57/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.8850 - accuracy: 0.2373 - top-5-accuracy: 0.8418\n",
      "Epoch 58/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.8583 - accuracy: 0.3051 - top-5-accuracy: 0.8588\n",
      "Epoch 59/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.8543 - accuracy: 0.3051 - top-5-accuracy: 0.8644\n",
      "Epoch 60/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.8573 - accuracy: 0.3220 - top-5-accuracy: 0.8136\n",
      "Epoch 61/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.8434 - accuracy: 0.2938 - top-5-accuracy: 0.8418\n",
      "Epoch 62/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.8475 - accuracy: 0.3164 - top-5-accuracy: 0.8588\n",
      "Epoch 63/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.8322 - accuracy: 0.3164 - top-5-accuracy: 0.8305\n",
      "Epoch 64/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.8583 - accuracy: 0.2938 - top-5-accuracy: 0.8362\n",
      "Epoch 65/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.8172 - accuracy: 0.2994 - top-5-accuracy: 0.8531\n",
      "Epoch 66/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 153ms/step - loss: 1.8308 - accuracy: 0.2712 - top-5-accuracy: 0.8588\n",
      "Epoch 67/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.8024 - accuracy: 0.3390 - top-5-accuracy: 0.8757\n",
      "Epoch 68/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.8257 - accuracy: 0.3107 - top-5-accuracy: 0.8644\n",
      "Epoch 69/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.7951 - accuracy: 0.3164 - top-5-accuracy: 0.8701\n",
      "Epoch 70/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.7775 - accuracy: 0.3446 - top-5-accuracy: 0.8757\n",
      "Epoch 71/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.7999 - accuracy: 0.3277 - top-5-accuracy: 0.8588\n",
      "Epoch 72/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.7912 - accuracy: 0.3446 - top-5-accuracy: 0.8757\n",
      "Epoch 73/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.7808 - accuracy: 0.3503 - top-5-accuracy: 0.8588\n",
      "Epoch 74/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.7543 - accuracy: 0.3672 - top-5-accuracy: 0.8588\n",
      "Epoch 75/160\n",
      "6/6 [==============================] - 1s 151ms/step - loss: 1.7614 - accuracy: 0.3446 - top-5-accuracy: 0.8701\n",
      "Epoch 76/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.7516 - accuracy: 0.3446 - top-5-accuracy: 0.8757\n",
      "Epoch 77/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.7589 - accuracy: 0.3390 - top-5-accuracy: 0.8418\n",
      "Epoch 78/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.7444 - accuracy: 0.3672 - top-5-accuracy: 0.8757\n",
      "Epoch 79/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.7449 - accuracy: 0.3503 - top-5-accuracy: 0.8701\n",
      "Epoch 80/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.7599 - accuracy: 0.3277 - top-5-accuracy: 0.8814\n",
      "Epoch 81/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.7118 - accuracy: 0.3616 - top-5-accuracy: 0.8531\n",
      "Epoch 82/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.7318 - accuracy: 0.3503 - top-5-accuracy: 0.8644\n",
      "Epoch 83/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.7878 - accuracy: 0.3277 - top-5-accuracy: 0.8644\n",
      "Epoch 84/160\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 1.7844 - accuracy: 0.3220 - top-5-accuracy: 0.8701\n",
      "Epoch 85/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.7202 - accuracy: 0.3842 - top-5-accuracy: 0.8701\n",
      "Epoch 86/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.6845 - accuracy: 0.3672 - top-5-accuracy: 0.8814\n",
      "Epoch 87/160\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 1.7043 - accuracy: 0.3672 - top-5-accuracy: 0.8870\n",
      "Epoch 88/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.7041 - accuracy: 0.3277 - top-5-accuracy: 0.8588\n",
      "Epoch 89/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.6347 - accuracy: 0.3842 - top-5-accuracy: 0.8757\n",
      "Epoch 90/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.6536 - accuracy: 0.4124 - top-5-accuracy: 0.8927\n",
      "Epoch 91/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.6227 - accuracy: 0.4068 - top-5-accuracy: 0.8757\n",
      "Epoch 92/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.6662 - accuracy: 0.3955 - top-5-accuracy: 0.8927\n",
      "Epoch 93/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.6395 - accuracy: 0.3955 - top-5-accuracy: 0.8588\n",
      "Epoch 94/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.6166 - accuracy: 0.4237 - top-5-accuracy: 0.8870\n",
      "Epoch 95/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.5983 - accuracy: 0.4181 - top-5-accuracy: 0.8757\n",
      "Epoch 96/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.5666 - accuracy: 0.4407 - top-5-accuracy: 0.8644\n",
      "Epoch 97/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.5046 - accuracy: 0.4633 - top-5-accuracy: 0.8870\n",
      "Epoch 98/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.5011 - accuracy: 0.4576 - top-5-accuracy: 0.8757\n",
      "Epoch 99/160\n",
      "6/6 [==============================] - 1s 169ms/step - loss: 1.4977 - accuracy: 0.4463 - top-5-accuracy: 0.8814\n",
      "Epoch 100/160\n",
      "6/6 [==============================] - 1s 176ms/step - loss: 1.5580 - accuracy: 0.4181 - top-5-accuracy: 0.8927\n",
      "Epoch 101/160\n",
      "6/6 [==============================] - 1s 177ms/step - loss: 1.6181 - accuracy: 0.3729 - top-5-accuracy: 0.8927\n",
      "Epoch 102/160\n",
      "6/6 [==============================] - 1s 186ms/step - loss: 1.5116 - accuracy: 0.4407 - top-5-accuracy: 0.8814\n",
      "Epoch 103/160\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 1.4772 - accuracy: 0.4802 - top-5-accuracy: 0.8983\n",
      "Epoch 104/160\n",
      "6/6 [==============================] - 1s 191ms/step - loss: 1.4664 - accuracy: 0.4746 - top-5-accuracy: 0.9040\n",
      "Epoch 105/160\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 1.4407 - accuracy: 0.4802 - top-5-accuracy: 0.8983\n",
      "Epoch 106/160\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 1.4949 - accuracy: 0.4859 - top-5-accuracy: 0.9096\n",
      "Epoch 107/160\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 1.5333 - accuracy: 0.4237 - top-5-accuracy: 0.9209\n",
      "Epoch 108/160\n",
      "6/6 [==============================] - 1s 163ms/step - loss: 1.5056 - accuracy: 0.4463 - top-5-accuracy: 0.8927\n",
      "Epoch 109/160\n",
      "6/6 [==============================] - 1s 188ms/step - loss: 1.4769 - accuracy: 0.4915 - top-5-accuracy: 0.9040\n",
      "Epoch 110/160\n",
      "6/6 [==============================] - 1s 165ms/step - loss: 1.3861 - accuracy: 0.5367 - top-5-accuracy: 0.9379\n",
      "Epoch 111/160\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 1.3089 - accuracy: 0.5650 - top-5-accuracy: 0.8983\n",
      "Epoch 112/160\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 1.2938 - accuracy: 0.5424 - top-5-accuracy: 0.8870\n",
      "Epoch 113/160\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 1.3054 - accuracy: 0.5876 - top-5-accuracy: 0.9040\n",
      "Epoch 114/160\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 1.2819 - accuracy: 0.5537 - top-5-accuracy: 0.9322\n",
      "Epoch 115/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.2780 - accuracy: 0.5706 - top-5-accuracy: 0.9266\n",
      "Epoch 116/160\n",
      "6/6 [==============================] - 1s 164ms/step - loss: 1.3229 - accuracy: 0.5198 - top-5-accuracy: 0.9379\n",
      "Epoch 117/160\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 1.2375 - accuracy: 0.5593 - top-5-accuracy: 0.9096\n",
      "Epoch 118/160\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 1.1779 - accuracy: 0.5876 - top-5-accuracy: 0.9492\n",
      "Epoch 119/160\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 1.2254 - accuracy: 0.5424 - top-5-accuracy: 0.9379\n",
      "Epoch 120/160\n",
      "6/6 [==============================] - 1s 174ms/step - loss: 1.1453 - accuracy: 0.5932 - top-5-accuracy: 0.9435\n",
      "Epoch 121/160\n",
      "6/6 [==============================] - 1s 173ms/step - loss: 1.0417 - accuracy: 0.6610 - top-5-accuracy: 0.9379\n",
      "Epoch 122/160\n",
      "6/6 [==============================] - 1s 190ms/step - loss: 1.0420 - accuracy: 0.6328 - top-5-accuracy: 0.9322\n",
      "Epoch 123/160\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 1.0611 - accuracy: 0.6215 - top-5-accuracy: 0.9605\n",
      "Epoch 124/160\n",
      "6/6 [==============================] - 1s 157ms/step - loss: 1.0827 - accuracy: 0.6045 - top-5-accuracy: 0.9435\n",
      "Epoch 125/160\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 1.0155 - accuracy: 0.6610 - top-5-accuracy: 0.9153\n",
      "Epoch 126/160\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.9740 - accuracy: 0.6497 - top-5-accuracy: 0.9661\n",
      "Epoch 127/160\n",
      "6/6 [==============================] - 1s 157ms/step - loss: 0.9726 - accuracy: 0.6780 - top-5-accuracy: 0.9548\n",
      "Epoch 128/160\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.9369 - accuracy: 0.6497 - top-5-accuracy: 0.9605\n",
      "Epoch 129/160\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 1.0282 - accuracy: 0.6554 - top-5-accuracy: 0.9435\n",
      "Epoch 130/160\n",
      "6/6 [==============================] - 1s 179ms/step - loss: 0.8939 - accuracy: 0.7062 - top-5-accuracy: 0.9548\n",
      "Epoch 131/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 157ms/step - loss: 0.8815 - accuracy: 0.6893 - top-5-accuracy: 0.9605\n",
      "Epoch 132/160\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.8697 - accuracy: 0.7006 - top-5-accuracy: 0.9548\n",
      "Epoch 133/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.7339 - accuracy: 0.7345 - top-5-accuracy: 0.9718\n",
      "Epoch 134/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.7396 - accuracy: 0.7288 - top-5-accuracy: 0.9774\n",
      "Epoch 135/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.7167 - accuracy: 0.7514 - top-5-accuracy: 0.9661\n",
      "Epoch 136/160\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.6369 - accuracy: 0.7910 - top-5-accuracy: 0.9718\n",
      "Epoch 137/160\n",
      "6/6 [==============================] - 1s 211ms/step - loss: 0.6877 - accuracy: 0.7684 - top-5-accuracy: 0.9774\n",
      "Epoch 138/160\n",
      "6/6 [==============================] - 1s 188ms/step - loss: 0.5448 - accuracy: 0.8136 - top-5-accuracy: 0.9887\n",
      "Epoch 139/160\n",
      "6/6 [==============================] - 1s 180ms/step - loss: 0.5350 - accuracy: 0.7910 - top-5-accuracy: 0.9774\n",
      "Epoch 140/160\n",
      "6/6 [==============================] - 1s 161ms/step - loss: 0.5829 - accuracy: 0.7853 - top-5-accuracy: 0.9887\n",
      "Epoch 141/160\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.8696 - accuracy: 0.7175 - top-5-accuracy: 0.9718\n",
      "Epoch 142/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.0642 - accuracy: 0.6102 - top-5-accuracy: 0.9661\n",
      "Epoch 143/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.9020 - accuracy: 0.6949 - top-5-accuracy: 0.9718\n",
      "Epoch 144/160\n",
      "6/6 [==============================] - 1s 171ms/step - loss: 1.0633 - accuracy: 0.6441 - top-5-accuracy: 0.9661\n",
      "Epoch 145/160\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 1.0526 - accuracy: 0.6328 - top-5-accuracy: 0.9661\n",
      "Epoch 146/160\n",
      "6/6 [==============================] - 1s 188ms/step - loss: 0.9723 - accuracy: 0.6497 - top-5-accuracy: 0.9718\n",
      "Epoch 147/160\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.7654 - accuracy: 0.7232 - top-5-accuracy: 0.9887\n",
      "Epoch 148/160\n",
      "6/6 [==============================] - 1s 177ms/step - loss: 0.6992 - accuracy: 0.7571 - top-5-accuracy: 0.9944\n",
      "Epoch 149/160\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.5701 - accuracy: 0.8249 - top-5-accuracy: 0.9831\n",
      "Epoch 150/160\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.5368 - accuracy: 0.8079 - top-5-accuracy: 1.0000\n",
      "Epoch 151/160\n",
      "6/6 [==============================] - 1s 168ms/step - loss: 0.5679 - accuracy: 0.7910 - top-5-accuracy: 0.9944\n",
      "Epoch 152/160\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.5607 - accuracy: 0.8136 - top-5-accuracy: 0.9887\n",
      "Epoch 153/160\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.4474 - accuracy: 0.8701 - top-5-accuracy: 0.9944\n",
      "Epoch 154/160\n",
      "6/6 [==============================] - 1s 163ms/step - loss: 0.4246 - accuracy: 0.8531 - top-5-accuracy: 0.9944\n",
      "Epoch 155/160\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.4689 - accuracy: 0.8418 - top-5-accuracy: 0.9944\n",
      "Epoch 156/160\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 0.5390 - accuracy: 0.8192 - top-5-accuracy: 0.9887\n",
      "Epoch 157/160\n",
      "6/6 [==============================] - 1s 170ms/step - loss: 0.7210 - accuracy: 0.7627 - top-5-accuracy: 0.9887\n",
      "Epoch 158/160\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.7009 - accuracy: 0.7288 - top-5-accuracy: 0.9944\n",
      "Epoch 159/160\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 0.6486 - accuracy: 0.7966 - top-5-accuracy: 0.9887\n",
      "Epoch 160/160\n",
      "6/6 [==============================] - 1s 164ms/step - loss: 0.5114 - accuracy: 0.8192 - top-5-accuracy: 0.9944\n",
      "4/4 [==============================] - 1s 73ms/step - loss: 4.1199 - accuracy: 0.1700 - top-5-accuracy: 0.5900\n",
      "Test accuracy: 17.0%\n",
      "Test top 5 accuracy: 59.0%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment():\n",
    "    # Initialize model\n",
    "    model = create_vivit_classifier(\n",
    "        tubelet_embedder=TubeletEmbedding(\n",
    "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE, strides=STRIDES\n",
    "        ),\n",
    "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
    "    )\n",
    "\n",
    "    # Compile the model with the optimizer, loss function\n",
    "    # and the metrics.\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Train the model.\n",
    "    _ = model.fit(trainloader, epochs=EPOCHS)\n",
    "\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(testloader)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = run_experiment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 30, 226, 22  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " tubelet_embedding_1 (TubeletEm  (None, 216, 128)    4147328     ['input_2[0][0]']                \n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " positional_encoder (Positional  (None, 216, 128)    27648       ['tubelet_embedding_1[0][0]']    \n",
      " Encoder)                                                                                         \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 216, 128)    256         ['positional_encoder[0][0]']     \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 216, 128)    66048       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 216, 128)     0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'positional_encoder[0][0]']     \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 216, 128)    256         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 216, 128)     131712      ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 216, 128)     0           ['sequential[0][0]',             \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 216, 128)    256         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 216, 128)    66048       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 216, 128)     0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 216, 128)    256         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 216, 128)     131712      ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 216, 128)     0           ['sequential_1[0][0]',           \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 216, 128)    256         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 216, 128)    66048       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 216, 128)     0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 216, 128)    256         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 216, 128)     131712      ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 216, 128)     0           ['sequential_2[0][0]',           \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 216, 128)    256         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 216, 128)    66048       ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 216, 128)     0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 216, 128)    256         ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 216, 128)     131712      ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 216, 128)     0           ['sequential_3[0][0]',           \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 216, 128)    256         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " multi_head_attention_4 (MultiH  (None, 216, 128)    66048       ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 216, 128)     0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 216, 128)    256         ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 216, 128)     131712      ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 216, 128)     0           ['sequential_4[0][0]',           \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 216, 128)    256         ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 216, 128)    66048       ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 216, 128)     0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 216, 128)    256         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 216, 128)     131712      ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 216, 128)     0           ['sequential_5[0][0]',           \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 216, 128)    256         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 216, 128)    66048       ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 216, 128)     0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 216, 128)    256         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 216, 128)     131712      ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 216, 128)     0           ['sequential_6[0][0]',           \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 216, 128)    256         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 216, 128)    66048       ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 216, 128)     0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 216, 128)    256         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 216, 128)     131712      ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 216, 128)     0           ['sequential_7[0][0]',           \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 216, 128)    256         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 216, 128)    66048       ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 216, 128)     0           ['multi_head_attention_8[0][0]', \n",
      "                                                                  'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 216, 128)    256         ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 216, 128)     131712      ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 216, 128)     0           ['sequential_8[0][0]',           \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 216, 128)    256         ['add_17[0][0]']                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 216, 128)    66048       ['layer_normalization_18[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 216, 128)     0           ['multi_head_attention_9[0][0]', \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 216, 128)    256         ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)      (None, 216, 128)     131712      ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 216, 128)     0           ['sequential_9[0][0]',           \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 216, 128)    256         ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['layer_normalization_20[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 8)            1032        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,158,984\n",
      "Trainable params: 6,158,984\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 30, 226, 226, 1)\n",
      "tf.Tensor(\n",
      "[0. 0. 6. 0. 5. 2. 7. 2. 2. 7. 7. 5. 7. 7. 4. 4. 4. 2. 2. 6. 7. 7. 7. 4.\n",
      " 6. 4. 3. 3. 6. 6. 5. 6.], shape=(32,), dtype=float32)\n",
      "1/1 [==============================] - 1s 768ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb22f8e9069c42c0ad0e18354db4fe81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(VBox(children=(HTML(value=\"'T: 0 | P: 1'\"), Box(children=(Image(value=b'GIF89a\\xe2\\x00\\xe2\\x"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_SAMPLES_VIZ = 25\n",
    "testsamples, labels = next(iter(testloader))\n",
    "print(testsamples.shape)\n",
    "print(labels)\n",
    "\n",
    "testsamples, labels = testsamples[:NUM_SAMPLES_VIZ], labels[:NUM_SAMPLES_VIZ]\n",
    "\n",
    "ground_truths = []\n",
    "preds = []\n",
    "videos = []\n",
    "\n",
    "for i, (testsample, label) in enumerate(zip(testsamples, labels)):\n",
    "    # Generate gif\n",
    "    with io.BytesIO() as gif:\n",
    "        imageio.mimsave(gif, (testsample.numpy() * 255).astype(\"uint8\"), \"GIF\", fps=5)\n",
    "        videos.append(gif.getvalue())\n",
    "\n",
    "    # Get model prediction\n",
    "    output = model.predict(tf.expand_dims(testsample, axis=0))[0]\n",
    "    pred = np.argmax(output, axis=0)\n",
    "\n",
    "    ground_truths.append(label.numpy().astype(\"int\"))\n",
    "    preds.append(pred)\n",
    "\n",
    "\n",
    "def make_box_for_grid(image_widget, fit):\n",
    "    \"\"\"Make a VBox to hold caption/image for demonstrating option_fit values.\n",
    "\n",
    "    Source: https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Styling.html\n",
    "    \"\"\"\n",
    "    # Make the caption\n",
    "    if fit is not None:\n",
    "        fit_str = \"'{}'\".format(fit)\n",
    "    else:\n",
    "        fit_str = str(fit)\n",
    "\n",
    "    h = ipywidgets.HTML(value=\"\" + str(fit_str) + \"\")\n",
    "\n",
    "    # Make the green box with the image widget inside it\n",
    "    boxb = ipywidgets.widgets.Box()\n",
    "    boxb.children = [image_widget]\n",
    "\n",
    "    # Compose into a vertical box\n",
    "    vb = ipywidgets.widgets.VBox()\n",
    "    vb.layout.align_items = \"center\"\n",
    "    vb.children = [h, boxb]\n",
    "    return vb\n",
    "\n",
    "\n",
    "boxes = []\n",
    "for i in range(NUM_SAMPLES_VIZ):\n",
    "    ib = ipywidgets.widgets.Image(value=videos[i], width=100, height=100)\n",
    "    true_class = str(ground_truths[i])\n",
    "    pred_class = str(preds[i])\n",
    "    caption = f\"T: {true_class} | P: {pred_class}\"\n",
    "\n",
    "    boxes.append(make_box_for_grid(ib, caption))\n",
    "\n",
    "ipywidgets.widgets.GridBox(\n",
    "    boxes, layout=ipywidgets.widgets.Layout(grid_template_columns=\"repeat(5, 200px)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "pred= model.predict(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(preds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    }
   ],
   "source": [
    "ground_truths = []\n",
    "preds = []\n",
    "videos = []\n",
    "for test in testloader:\n",
    "    testsamples, labels = next(iter(testloader))\n",
    "    for i, (testsample, label) in enumerate(zip(testsamples, labels)):\n",
    "        # Get model prediction\n",
    "        output = model.predict(tf.expand_dims(testsample, axis=0))[0]\n",
    "        pred = np.argmax(output, axis=0)\n",
    "\n",
    "        ground_truths.append(label.numpy().astype(\"int\"))\n",
    "        preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(preds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "con_mat = confusion_matrix(test_labels, preds[:100])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=con_mat)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.03      0.12      0.05         8\n",
      "           2       0.17      0.17      0.17        12\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.00      0.00      0.00        19\n",
      "           5       0.11      0.43      0.18         7\n",
      "           6       0.11      0.06      0.08        16\n",
      "           7       0.06      0.06      0.06        17\n",
      "\n",
      "    accuracy                           0.08       100\n",
      "   macro avg       0.06      0.11      0.07       100\n",
      "weighted avg       0.06      0.08      0.06       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacobo\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacobo\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacobo\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_labels, preds[:100],labels=[0,1,2,3,4,5,6,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bovine-gpu",
   "language": "python",
   "name": "bovine-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
